{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer 구현하기_2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1eVDFoTEtcD-QRVAOyP6_XU3WAKD3woEe",
      "authorship_tag": "ABX9TyMbt05iMcWbUoy4Cq9Oz+mw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/heejvely/NLP_models/blob/main/Transformer_%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 코드 참조: https://paul-hyun.github.io/transformer-02/"
      ],
      "metadata": {
        "id": "omFSsOGKMjnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0. Imports"
      ],
      "metadata": {
        "id": "Tqg3qLHDNXau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentencepiece import\n",
        "!pip install sentencepiece\n",
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNyswLZNM9dk",
        "outputId": "8a1311e1-01c2-49c9-ae90-7c0ced0bb8b3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 36.8 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 8.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=9177cd47afa62073e1d73d5ccdcc70f47e8a4843547ebd776ea08792e8390703\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "from tqdm import tqdm, tqdm_notebook, trange\n",
        "import sentencepiece as spm\n",
        "import wget\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "TVWQtvVwNWrP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Vocab\n",
        "\n",
        "sentencepiece를 활용해 만든 vocab을 이용해 텍스트를 입력 tensor로 변경"
      ],
      "metadata": {
        "id": "7pbW-Pk5Mymn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwEdp5QKMUZa",
        "outputId": "0356aafe-1527-45a2-8306-147db334cdfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import sentencepiece as spm\n",
        "# vocab loading\n",
        "vocab_file = '/content/drive/MyDrive/colab/NLP_모델/kowiki_corpus/kowiki.model'\n",
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SentencePieceProcessor class 참고\n",
        ": https://github.com/google/sentencepiece/blob/master/doc/api.md"
      ],
      "metadata": {
        "id": "-GKuRgqdOpqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "help(spm.SentencePieceProcessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDuzjzwWOIS5",
        "outputId": "3495205a-75ea-4007-d818-5f102f14455a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class SentencePieceProcessor in module sentencepiece:\n",
            "\n",
            "class SentencePieceProcessor(builtins.object)\n",
            " |  SentencePieceProcessor(model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, enable_sampling=False, nbest_size=-1, alpha=0.1)\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  Decode(self, input)\n",
            " |      Decode processed id or token sequences.\n",
            " |  \n",
            " |  DecodeIds = DecodeIdsWithCheck(self, ids)\n",
            " |  \n",
            " |  DecodeIdsAsSerializedProto = DecodeIdsAsSerializedProtoWithCheck(self, ids)\n",
            " |  \n",
            " |  DecodeIdsAsSerializedProtoWithCheck(self, ids)\n",
            " |  \n",
            " |  DecodeIdsWithCheck(self, ids)\n",
            " |  \n",
            " |  DecodePieces(self, pieces)\n",
            " |  \n",
            " |  DecodePiecesAsSerializedProto(self, pieces)\n",
            " |  \n",
            " |  Detokenize = Decode(self, input)\n",
            " |  \n",
            " |  Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, enable_sampling=None, nbest_size=None, alpha=None)\n",
            " |      Encode text input to segmented ids or tokens.\n",
            " |      \n",
            " |      Args:\n",
            " |      input: input string. accepsts list of string.\n",
            " |      out_type: output type. int or str.\n",
            " |      add_bos: Add <s> to the result (Default = false)\n",
            " |      add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
            " |        reversing (if enabled).\n",
            " |      reverse: Reverses the tokenized sequence (Default = false)\n",
            " |      nbest_size: sampling parameters for unigram. Invalid for BPE-Dropout.\n",
            " |                  nbest_size = {0,1}: No sampling is performed.\n",
            " |                  nbest_size > 1: samples from the nbest_size results.\n",
            " |                  nbest_size < 0: assuming that nbest_size is infinite and samples\n",
            " |                    from the all hypothesis (lattice) using\n",
            " |                    forward-filtering-and-backward-sampling algorithm.\n",
            " |      alpha: Soothing parameter for unigram sampling, and merge probability for\n",
            " |             BPE-dropout (probablity 'p' in BPE-dropout paper).\n",
            " |  \n",
            " |  EncodeAsIds(self, input)\n",
            " |  \n",
            " |  EncodeAsPieces(self, input)\n",
            " |  \n",
            " |  EncodeAsSerializedProto(self, input)\n",
            " |  \n",
            " |  GetEncoderVersion(self)\n",
            " |  \n",
            " |  GetPieceSize(self)\n",
            " |  \n",
            " |  GetScore = _batched_func(self, arg)\n",
            " |  \n",
            " |  IdToPiece = _batched_func(self, arg)\n",
            " |  \n",
            " |  Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, enable_sampling=False, nbest_size=-1, alpha=0.1)\n",
            " |      Initialzie sentencepieceProcessor.\n",
            " |      \n",
            " |      Args:\n",
            " |        model_file: The sentencepiece model file path.\n",
            " |        model_proto: The sentencepiece model serialized proto.\n",
            " |        out_type: output type. int or str.\n",
            " |        add_bos: Add <s> to the result (Default = false)\n",
            " |        add_eos: Add </s> to the result (Default = false) <s>/</s> is added after\n",
            " |          reversing (if enabled).\n",
            " |        reverse: Reverses the tokenized sequence (Default = false)\n",
            " |        nbest_size: sampling parameters for unigram. Invalid for BPE-Dropout.\n",
            " |                    nbest_size = {0,1}: No sampling is performed.\n",
            " |                    nbest_size > 1: samples from the nbest_size results.\n",
            " |                    nbest_size < 0: assuming that nbest_size is infinite and samples\n",
            " |                      from the all hypothesis (lattice) using\n",
            " |                      forward-filtering-and-backward-sampling algorithm.\n",
            " |        alpha: Soothing parameter for unigram sampling, and dropout probability of\n",
            " |          merge operations for BPE-dropout.\n",
            " |  \n",
            " |  IsByte = _batched_func(self, arg)\n",
            " |  \n",
            " |  IsControl = _batched_func(self, arg)\n",
            " |  \n",
            " |  IsUnknown = _batched_func(self, arg)\n",
            " |  \n",
            " |  IsUnused = _batched_func(self, arg)\n",
            " |  \n",
            " |  Load(self, model_file=None, model_proto=None)\n",
            " |      Overwride SentencePieceProcessor.Load to support both model_file and model_proto.\n",
            " |      \n",
            " |      Args:\n",
            " |        model_file: The sentencepiece model file path.\n",
            " |        model_proto: The sentencepiece model serialized proto. Either `model_file`\n",
            " |          or `model_proto` must be set.\n",
            " |  \n",
            " |  LoadFromFile(self, arg)\n",
            " |  \n",
            " |  LoadFromSerializedProto(self, serialized)\n",
            " |  \n",
            " |  LoadVocabulary(self, filename, threshold)\n",
            " |  \n",
            " |  NBestEncodeAsIds(self, input, nbest_size)\n",
            " |  \n",
            " |  NBestEncodeAsPieces(self, input, nbest_size)\n",
            " |  \n",
            " |  NBestEncodeAsSerializedProto(self, input, nbest_size)\n",
            " |  \n",
            " |  PieceToId = _batched_func(self, arg)\n",
            " |  \n",
            " |  ResetVocabulary(self)\n",
            " |  \n",
            " |  SampleEncodeAsIds(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  SampleEncodeAsPieces(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  SampleEncodeAsSerializedProto(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  SetDecodeExtraOptions(self, extra_option)\n",
            " |  \n",
            " |  SetEncodeExtraOptions(self, extra_option)\n",
            " |  \n",
            " |  SetEncoderVersion(self, encoder_version)\n",
            " |  \n",
            " |  SetVocabulary(self, valid_vocab)\n",
            " |  \n",
            " |  Tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, enable_sampling=None, nbest_size=None, alpha=None)\n",
            " |  \n",
            " |  __getitem__(self, piece)\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __init__ = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, enable_sampling=False, nbest_size=-1, alpha=0.1)\n",
            " |  \n",
            " |  __len__(self)\n",
            " |  \n",
            " |  __repr__ = _swig_repr(self)\n",
            " |  \n",
            " |  __setstate__(self, serialized_model_proto)\n",
            " |  \n",
            " |  bos_id(self)\n",
            " |  \n",
            " |  decode = Decode(self, input)\n",
            " |  \n",
            " |  decode_ids = DecodeIdsWithCheck(self, ids)\n",
            " |  \n",
            " |  decode_ids_as_serialized_proto = DecodeIdsAsSerializedProtoWithCheck(self, ids)\n",
            " |  \n",
            " |  decode_ids_as_serialized_proto_with_check = DecodeIdsAsSerializedProtoWithCheck(self, ids)\n",
            " |  \n",
            " |  decode_ids_with_check = DecodeIdsWithCheck(self, ids)\n",
            " |  \n",
            " |  decode_pieces = DecodePieces(self, pieces)\n",
            " |  \n",
            " |  decode_pieces_as_serialized_proto = DecodePiecesAsSerializedProto(self, pieces)\n",
            " |  \n",
            " |  detokenize = Decode(self, input)\n",
            " |  \n",
            " |  encode = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, enable_sampling=None, nbest_size=None, alpha=None)\n",
            " |  \n",
            " |  encode_as_ids = EncodeAsIds(self, input)\n",
            " |  \n",
            " |  encode_as_pieces = EncodeAsPieces(self, input)\n",
            " |  \n",
            " |  encode_as_serialized_proto = EncodeAsSerializedProto(self, input)\n",
            " |  \n",
            " |  eos_id(self)\n",
            " |  \n",
            " |  get_encoder_version = GetEncoderVersion(self)\n",
            " |  \n",
            " |  get_piece_size = GetPieceSize(self)\n",
            " |  \n",
            " |  get_score = _batched_func(self, arg)\n",
            " |  \n",
            " |  id_to_piece = _batched_func(self, arg)\n",
            " |  \n",
            " |  init = Init(self, model_file=None, model_proto=None, out_type=<class 'int'>, add_bos=False, add_eos=False, reverse=False, enable_sampling=False, nbest_size=-1, alpha=0.1)\n",
            " |  \n",
            " |  is_byte = _batched_func(self, arg)\n",
            " |  \n",
            " |  is_control = _batched_func(self, arg)\n",
            " |  \n",
            " |  is_unknown = _batched_func(self, arg)\n",
            " |  \n",
            " |  is_unused = _batched_func(self, arg)\n",
            " |  \n",
            " |  load = Load(self, model_file=None, model_proto=None)\n",
            " |  \n",
            " |  load_from_file = LoadFromFile(self, arg)\n",
            " |  \n",
            " |  load_from_serialized_proto = LoadFromSerializedProto(self, serialized)\n",
            " |  \n",
            " |  load_vocabulary = LoadVocabulary(self, filename, threshold)\n",
            " |  \n",
            " |  nbest_encode_as_ids = NBestEncodeAsIds(self, input, nbest_size)\n",
            " |  \n",
            " |  nbest_encode_as_pieces = NBestEncodeAsPieces(self, input, nbest_size)\n",
            " |  \n",
            " |  nbest_encode_as_serialized_proto = NBestEncodeAsSerializedProto(self, input, nbest_size)\n",
            " |  \n",
            " |  pad_id(self)\n",
            " |  \n",
            " |  piece_size(self)\n",
            " |  \n",
            " |  piece_to_id = _batched_func(self, arg)\n",
            " |  \n",
            " |  reset_vocabulary = ResetVocabulary(self)\n",
            " |  \n",
            " |  sample_encode_as_ids = SampleEncodeAsIds(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  sample_encode_as_pieces = SampleEncodeAsPieces(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  sample_encode_as_serialized_proto = SampleEncodeAsSerializedProto(self, input, nbest_size, alpha)\n",
            " |  \n",
            " |  serialized_model_proto(self)\n",
            " |  \n",
            " |  set_decode_extra_options = SetDecodeExtraOptions(self, extra_option)\n",
            " |  \n",
            " |  set_encode_extra_options = SetEncodeExtraOptions(self, extra_option)\n",
            " |  \n",
            " |  set_encoder_version = SetEncoderVersion(self, encoder_version)\n",
            " |  \n",
            " |  set_vocabulary = SetVocabulary(self, valid_vocab)\n",
            " |  \n",
            " |  tokenize = Encode(self, input, out_type=None, add_bos=None, add_eos=None, reverse=None, enable_sampling=None, nbest_size=None, alpha=None)\n",
            " |  \n",
            " |  unk_id(self)\n",
            " |  \n",
            " |  vocab_size(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __swig_destroy__ = delete_SentencePieceProcessor(...)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  thisown\n",
            " |      The membership flag\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Config\n",
        "\n",
        "설정을 json 형태로 저장하고, 이를 읽어서 처리하는 간단한 클래스"
      ],
      "metadata": {
        "id": "F6Aa0FwMMz9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"configuration json을 읽어들이는 class\"\"\"\n",
        "class Config(dict):\n",
        "  __getattr__ = dict.__getitem__\n",
        "  __setarrt__ = dict.__setitem__\n",
        "\n",
        "  @classmethod\n",
        "  def load(cls, file):\n",
        "    with open(file, 'r') as f:\n",
        "      config = json.loads(f.read())\n",
        "      return Config(config)"
      ],
      "metadata": {
        "id": "15KSw-8fM79x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = Config({\n",
        "    'n_enc_vocab':len(vocab),\n",
        "    'n_dec_vocab':len(vocab),\n",
        "    'n_enc_seq':256,\n",
        "    'n_dec_seq':256,\n",
        "    'n_layer':6,\n",
        "    'd_hidn':256,\n",
        "    'i_pad':0,\n",
        "    'd_ff':1024,\n",
        "    'n_head':4,\n",
        "    'd_head':64,\n",
        "    'dropout':0.1,\n",
        "    'layer_norm_epsilon':1e-12\n",
        "})\n",
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSFpfW08N8Hz",
        "outputId": "d71e5978-6d94-4d7c-feb9-caf9fc8eb1be"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Common Class\n",
        "\n",
        "Transformer 구현하기_1.ipynb 에서 구현한 'Position Embedding','Multi-Head Attention','Feed Forward'의 코드"
      ],
      "metadata": {
        "id": "Jzs2ENBtOaVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Position Encoding\n",
        "\n",
        "Position Embedding의 초기 값을 구하는 함수\n",
        "1. 각 position별 hidden index별 angle 값을 구합니다.\n",
        "2. hidden 짝수 index의 angle값의 sin값을 구합니다.\n",
        "3. hidden 홀수 index의 angle값의 cos값을 구합니다."
      ],
      "metadata": {
        "id": "2b7EceoKP62L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"sinusoid position encoding\"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "  def cal_angle(position, i_hidn):\n",
        "    return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "  def get_posi_angle_vec(position):\n",
        "    return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "  sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])  # 1. 각 position별 hidden index별 angle 값을 구합니다.\n",
        "  sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])                         # 2. hidden 짝수 index의 angle값의 sin값을 구합니다.\n",
        "  sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])                         # 3. hidden 홀수 index의 angle값의 cos값을 구합니다.\n",
        "\n",
        "  return sinusoid_table"
      ],
      "metadata": {
        "id": "6n6xR_-dOYV1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Pad Mask\n",
        "\n",
        "Attention을 구할 때 Padding 부분을 제외하기 위한 Mask를 구하는 함수\n",
        "\n",
        "1. K의 값 중에 Pad인 부분을 True로 변경합니다.(나머지는 False)\n",
        "2. 구해진 값의 크기를 Q-len, K-len 되도록 변경합니다."
      ],
      "metadata": {
        "id": "ey2_NMszQEm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"attention pad mask\"\"\"\n",
        "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
        "  batch_size, len_q = seq_q.size()\n",
        "  batch_size, len_k = seq_k.size()\n",
        "  pad_attn_mask = seq_k.data.eq(i_pad)                                              # 1. K의 값 중에 Pad인 부분을 True로 변경합니다.(나머지는 False)\n",
        "  pad_attn_mask = pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)       # 2. 구해진 값의 크기를 Q-len, K-len 되도록 변경합니다.\n",
        "  return pad_attn_mask"
      ],
      "metadata": {
        "id": "Ozn9JwhOPHIG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Attention Decoder Mask\n",
        "\n",
        "Decoder의 'Masked Multi Head Attention'에서 사용할 Mask를 구하는 함수입니다.\n",
        "\n",
        "현재 단어와 이전 단어는 볼 수 있고 다음 단어는 볼 수 없도록 Masking 합니다.\n",
        "\n",
        "1. 모든 값이 1인 Q-len, K-leb 테이블을 생성합니다.\n",
        "2. 대각선을 기준으로 아래쪽을 0으로 만듭니다."
      ],
      "metadata": {
        "id": "2tL99-xMQ7P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"attention decoder mask\"\"\"\n",
        "def get_attn_decoder_mask(seq):\n",
        "  subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1)) # 1. 모든 값이 1인 Q-len, K-leb 테이블을 생성합니다.\n",
        "  subsequent_mask = subsequent_mask.triu(diafonal=1)                                                 # 2. 대각선을 기준으로 아래쪽을 0으로 만듭니다.\n",
        "  return subsequent_mask"
      ],
      "metadata": {
        "id": "g9LhHwhmQ4fw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scaled Dot Product Attention\n",
        "\n",
        "Scaled Dot Product Attention을 구하는 클래스\n",
        "\n",
        "1. Q * K.transpose를 구합니다.\n",
        "2. K-dimention에 루트를 취한 값으로 나눠 줍니다.\n",
        "3. Mask를 적용합니다.\n",
        "4. Softmax를 취해 각 단어의 가중치 확률분포 attn_prob를 구합니다.\n",
        "5. attn_prob * V를 구합니다. 구한 값은 Q에 대한 V의 가중치 합 벡터입니다."
      ],
      "metadata": {
        "id": "PMpcf2hGRowa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"scale dot product attention\"\"\"\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "    self.dopout= nn.Dropout(config.dropout)\n",
        "    self.scale = 1 / (self.config.d_head ** 0.5)\n",
        "\n",
        "  def forward(self, Q, K, V, attn_mask):\n",
        "    scores = torch.matmul(Q, K.transpose(-1, -2))     # 1. Q * K.transpose를 구합니다.\n",
        "    scores = scores.mul(self.scale)                   # 2. K-dimention에 루트를 취한 값으로 나눠 줍니다.\n",
        "    scores.masked_fill_(attn_mask, -1e9)              # 3. Mask를 적용합니다.\n",
        "\n",
        "    attn_prob = nn.Softmax(dim= -1)(scores)           # 4. Softmax를 취해 각 단어의 가중치 확률분포 attn_prob를 구합니다.\n",
        "    attn_prob = self.dropout(attn_prob)               # 5. attn_prob * V를 구합니다. 구한 값은 Q에 대한 V의 가중치 합 벡터입니다.\n",
        "\n",
        "    context = torch.matmul(attn_prob, V)\n",
        "\n",
        "    return context, attn_prob"
      ],
      "metadata": {
        "id": "WdOQ09aBRmnS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Head Attention\n",
        "\n",
        "Multi-Head Attention을 구하는 클래스\n",
        "\n",
        "1. Q * W_Q를 한 후 multi-head로 나눕니다.\n",
        "2. K * W_K를 한 후 multi-head로 나눕니다.\n",
        "3. V * W_V를 한 후 multi-head로 나눕니다.\n",
        "4. ScaledDotProductAttention 클래스를 이용해 각 head 별 Attention을 구합니다.\n",
        "5. 여러 개의 head를 1개로 합칩니다.\n",
        "6. Linear를 취해 최종 Multi-Head Attention값을 구합니다."
      ],
      "metadata": {
        "id": "RklKvjm9TAD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"multi head attention\"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "    self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "    self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
        "    self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
        "    self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self, Q, K, V, attn_mask):\n",
        "    batch_size = Q.size(0)\n",
        "    q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)                   # 1. Q * W_Q를 한 후 multi-head로 나눕니다.\n",
        "    k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)                   # 2. K * W_K를 한 후 multi-head로 나눕니다.\n",
        "    v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)                   # 3. V * W_V를 한 후 multi-head로 나눕니다.\n",
        "\n",
        "    attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n",
        "\n",
        "    context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)                                             # 4. ScaledDotProductAttention 클래스를 이용해 각 head 별 Attention을 구합니다.\n",
        "    context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)    # 5. 여러 개의 head를 1개로 합칩니다.\n",
        "    output = self.linear(context)                                                                                   # 6. Linear를 취해 최종 Multi-Head Attention값을 구합니다.\n",
        "    output = self.dropout(output)\n",
        "    \n",
        "    return output, attn_prob\n"
      ],
      "metadata": {
        "id": "jcfgPFY8S-0u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feed Forward\n",
        "\n",
        "FeedForward를 처리하는 클래스입니다.\n",
        "\n",
        "1. Linear를 실행하여 shape을 d_ff(hidden * 4)크기로 키웁니다.\n",
        "2. activation 함수(relu or gelu)를 실행합니다.\n",
        "3. Linear를 실행하여 shape을 hidden 크기로 줄입니다."
      ],
      "metadata": {
        "id": "dj9aEP3HVyZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"feed forward\"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.conv1 = nn.Conv1d(in_channels = self.config.d_hidn, out_channels = self.config.d_ff, kernel_size=1)\n",
        "    self.conv2 = nn.Conv1d(in_channels = self.congif.d_ff, out_channels = self.config.d_hidn, kernel_size=1)\n",
        "    self.active = F.gelu\n",
        "    self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    output = self.conv1(inputs.transpose(1, 2))     # 1. Linear를 실행하여 shape을 d_ff(hidden * 4)크기로 키웁니다.\n",
        "    output = self.active(output)                    # 2. activation 함수(relu or gelu)를 실행합니다.\n",
        "\n",
        "    output = self.conv2(output).transpose(1, 2)     # 3. Linear를 실행하여 shape을 hidden 크기로 줄입니다.\n",
        "    output = self.dropout(output)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "zT527TcmVw6q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Encoder"
      ],
      "metadata": {
        "id": "IOw--0ERbdiq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder layer\n",
        "\n",
        "Encoder에서 루프를 돌며 처리할 수 있도록 EncoderLayer를 정의하고 여러 개 만들어서 실행\n",
        "\n",
        "1. Multi-Head Attention을 수행합니다. Q, K, V 모두 동일한 값을 사용하는 self-attention입니다.\n",
        "2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "3. 2번의 결과를 입력으로 Feed Forward를 실행합니다.\n",
        "4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행합니다."
      ],
      "metadata": {
        "id": "tWuxESpiXq3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"encoder layer\"\"\"\n",
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.self_attn = MultiHeadAttention(self.config)\n",
        "    self.layer = norm1 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
        "    self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "    self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
        "\n",
        "  def forward(self, inputs, attn_mask):\n",
        "    attn_outputs, attn_prob = self.self_attn(inputs, inputs, inputs,attn_mask)    # 1. Multi-Head Attention을 수행합니다. Q, K, V 모두 동일한 값을 사용하는 self-attention입니다.\n",
        "    attn_outputs = self.layer_norm1(inputs + attn_outputs)                        # 2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "\n",
        "    ffn_outputs = self.pos_ffn(attn_outputs)                                      # 3. 2번의 결과를 입력으로 Feed Forward를 실행합니다.\n",
        "    ffn_outputs = self.layer_norm2(ffn_outputs + attn_outputs)                    # 4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "\n",
        "    return ffn_outputs, attn_prob"
      ],
      "metadata": {
        "id": "P2fcz_tXXaIZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder\n",
        "Encoder 클래스\n",
        "\n",
        "1. 입력에 대한 Position 값을 구합니다.\n",
        "2. Input Embedding과 Position Embedding을 구한 후 더합니다.\n",
        "3. 입력에 대한 attention pad mask를 구합니다.\n",
        "4. for 루프를 돌며 각 layer를 실행합니다. layer의 입력은 이전 layer의 출력 값입니다."
      ],
      "metadata": {
        "id": "a3ytSH9aZYDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"encoder\"\"\"\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.enc_emb = nn.Embedding(self.config.n_enc_vocav, self.config.d_hidn)\n",
        "    sinusoid_table = torch.FloatTensort(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n",
        "    self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n",
        "\n",
        "    self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self, config.n_layer)])\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    # 1. 입력에 대한 Position 값을 구합니다.\n",
        "    positions = torch.arange(inputs.size(1), device = inputs.device, dtype=inputs.dtype)\n",
        "    pos_mask = inputs.eq(self.config.i_pad)\n",
        "    positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "    outputs = self.enc_emb(inputs) + self.pos_emb(positions)          # 2. Input Embedding과 Position Embedding을 구한 후 더합니다.\n",
        "\n",
        "    attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)  # 3. 입력에 대한 attention pad mask를 구합니다.\n",
        "\n",
        "    attn_probs = []\n",
        "    for layer in self.layers:\n",
        "      outputs, attn_prob = layer(outputs, attn_mask)                  # 4. for 루프를 돌며 각 layer를 실행합니다. layer의 입력은 이전 layer의 출력 값입니다.\n",
        "      attn_probs.append(attn_prob)\n",
        "\n",
        "    return outputs, attn_probs"
      ],
      "metadata": {
        "id": "XDkjdsC9ZWoL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Decoder"
      ],
      "metadata": {
        "id": "arYYs5DGbV85"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder Layer\n",
        "\n",
        "Decoder에서 루프를 돌며 처리할 수 있도록 DecoderLayer를 정의하고 여러 개 만들어서 실행\n",
        "\n",
        "1. Multi-Head Attention을 수행합니다.\n",
        "- Q, K, V 모두 동일한 값을 사용하는 self-attention입니다.\n",
        "2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "3. Encoder-Decoder Multi-Head Attention을 수행합니다.\n",
        "- Q: 2번의 결과\n",
        "- K, V: Encoder 결과\n",
        "4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "5. 4번의 결과를 입력으로 FeedForward를 실행합니다.\n",
        "6. 5번의 결과와 4번의 결과(residual)을 더한 후 LayerNorm을 실행합니다."
      ],
      "metadata": {
        "id": "8ExJrN8YbfDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"decoder layer\"\"\"\n",
        "class DecoderLayer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.self_attn = MultiHeadAttention(self.config)\n",
        "    self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
        "    self.dec_enc_attn = MultiHeadAttention(self.config)\n",
        "    self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
        "    self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
        "    self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
        "\n",
        "  def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
        "    self_attn_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)      # 1. Multi-Head Attention을 수행합니다. - Q, K, V 모두 동일한 값을 사용하는 self-attention입니다.\n",
        "    self_attn_outputs = self.layer_norm1(dec_inputs + self_attn_outputs)                                        # 2. 1번의 결과와 input(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "\n",
        "    # 3. Encoder-Decoder Multi-Head Attention을 수행합니다.\n",
        "    # - Q: 2번의 결과\n",
        "    # - K, V: Encoder 결과\n",
        "    dec_enc_attn_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_attn_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
        "    dec_enc_attn_outputs = self.layer_norm2(self_attn_outputs + dec_enc_attn_outputs)                           # 4. 3번의 결과와 2번의 결과(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "\n",
        "    ffn_outputs = self.pos_ffn(dec_enc_attn_outputs)                                                            # 5. 4번의 결과를 입력으로 FeedForward를 실행합니다.\n",
        "    ffn_outputs = self.layer_norm3(dec_enc_attn_outputs + ffn_outputs)                                          # 6. 5번의 결과와 4번의 결과(residual)을 더한 후 LayerNorm을 실행합니다.\n",
        "    \n",
        "    return ffn_outputs, self_attn_prob, dec_enc_attn_prob"
      ],
      "metadata": {
        "id": "ptYhWHItbRaI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder\n",
        "Decoder 클래스\n",
        "\n",
        "1. 입력에 대한 Position 값을 구합니다.\n",
        "2. Input Embedding과 Position Embedding을 구한 후 더합니다.\n",
        "3. 입력에 대한 attention pad mask를 구합니다.\n",
        "4. 입력에 대한 decoder attention mask를 구합니다.\n",
        "5. attention pad mask와 decoder attention mask 중 1곳이라도 mask 되어 있는 부분이 mask 되도록 attention mask를 구합니다.\n",
        "6. Q(decoder input), K(encoder output)에 대한 attention mask를 구합니다.\n",
        "7. for 루프를 돌며 각 layer를 실행합니다.\n",
        "- layer의 입력은 이전 layer의 출력 값입니다."
      ],
      "metadata": {
        "id": "ySTLJ0FJeUSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"decoder\"\"\"\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
        "    sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n",
        "    self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze = True)\n",
        "\n",
        "    self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
        "\n",
        "  def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
        "    # 1. 입력에 대한 Position 값을 구합니다.\n",
        "    positions = torch.arnage(dec_inputs.size(1), device = dec_inputs.device, dtype = dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1).contiguous()+ 1)\n",
        "    pos_mask = dec_inputs.eq(self.config.i_pad)\n",
        "    positions.masked_fill_(pos_mask, 0)\n",
        "\n",
        "    dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)                    # 2. Input Embedding과 Position Embedding을 구한 후 더합니다.\n",
        "\n",
        "    dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)    # 3. 입력에 대한 attention pad mask를 구합니다.\n",
        "    dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)                           # 4. 입력에 대한 decoder attention mask를 구합니다.\n",
        "    dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)       # 5. attention pad mask와 decoder attention mask 중 1곳이라도 mask 되어 있는 부분이 mask 되도록 attention mask를 구합니다.\n",
        "    dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)    # 6. Q(decoder input), K(encoder output)에 대한 attention mask를 구합니다.\n",
        "\n",
        "    self_attn_probs, dec_enc_attn_probs = [], []\n",
        "    # 7. for 루프를 돌며 각 layer를 실행합니다.\n",
        "    # - layer의 입력은 이전 layer의 출력 값입니다.\n",
        "    for layer in self.layers:\n",
        "      dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n",
        "      self_attn_probs.append(self_attn_prob)\n",
        "      dec_enc_attn_probs.append(dec_enc_attn_prob)\n",
        "    return dec_outputs, self_attn_probs, dec_enc_attn_probs"
      ],
      "metadata": {
        "id": "l9m3im8MeSF-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Transformer\n",
        "\n",
        "Transformer 클래스\n",
        "\n",
        "1. Encoder Input을 입력으로 Encoder를 실행합니다.\n",
        "2. Encoder Output과 Decoder Input을 입력으로 Decoder를 실행합니다."
      ],
      "metadata": {
        "id": "5Pw-lqNihZy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"transformer\"\"\"\n",
        "class Transformer(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.encoder = Encoder(self.config)\n",
        "    self.decoder = Decoder(self.config)\n",
        "\n",
        "  def forward(self, enc_inputs, dec_inputs):\n",
        "    enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)                                                 # 1. Encoder Input을 입력으로 Encoder를 실행합니다.\n",
        "    dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)    # 2. Encoder Output과 Decoder Input을 입력으로 Decoder를 실행합니다.\n",
        "    return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"
      ],
      "metadata": {
        "id": "wQGaSlHbhV58"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}